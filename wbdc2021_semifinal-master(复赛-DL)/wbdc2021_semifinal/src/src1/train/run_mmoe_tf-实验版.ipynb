{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e0a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install deepctr==0.8.5 --no-deps\n",
    "# ! pip install torch==1.7.0 torchvision==0.8.1 \n",
    "# ! pip install tensorflow-gpu==1.13.1\n",
    "# ! pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1cb0fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR(目录): /home/tione/notebook\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../config/')\n",
    "from config_prosper import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import time\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names,VarLenSparseFeat\n",
    "from mytools.utils.myfile import savePkl,loadPkl\n",
    "from mmoe_tf import MMOE\n",
    "from evaluation import evaluate_deepctr\n",
    "from tensorflow.python.keras.utils import multi_gpu_model\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from deepctr.feature_column import build_input_features, input_from_feature_columns\n",
    "from deepctr.layers.utils import combined_dnn_input\n",
    "from deepctr.layers.core import PredictionLayer, DNN\n",
    "\n",
    "from tensorflow.python.keras.initializers import glorot_normal\n",
    "from tensorflow.python.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1443bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU相关设置\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# 设置GPU按需增长\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0294c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFeedinfo():\n",
    "    feed = loadPkl(FEED_INFO_DEAL)\n",
    "    feed[[\"bgm_song_id\", \"bgm_singer_id\"]] += 1  # 0 用于填未知\n",
    "    feed[[\"bgm_song_id\", \"bgm_singer_id\", \"videoplayseconds\"]] = \\\n",
    "        feed[[\"bgm_song_id\", \"bgm_singer_id\", \"videoplayseconds\"]].fillna(0)\n",
    "    feed['bgm_song_id'] = feed['bgm_song_id'].astype('int64')\n",
    "    feed['bgm_singer_id'] = feed['bgm_singer_id'].astype('int64')\n",
    "    print('feedinfo loading over...')\n",
    "    return feed\n",
    "\n",
    "def getFeedembeddings(df):\n",
    "    #feedembeddings 降维\n",
    "\n",
    "    feed_embedding_path = os.path.join(FEATURE_PATH,'feedembedings.pkl')\n",
    "    feed_embeddings = loadPkl(feed_embedding_path)\n",
    "    df = df.merge(feed_embeddings,on='feedid',how='left')\n",
    "    dense = [x for x in list(feed_embeddings.columns) if x != 'feedid' ]\n",
    "    \n",
    "    return df,dense\n",
    "\n",
    "def getSvdembeddings(df):\n",
    "    dense = []\n",
    "    #userid-feedid svd\n",
    "    svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'svd_userid_feedid_embedding.pkl'))\n",
    "    df = df.merge(svd_embedding,on = ['userid'],how='left')\n",
    "    dense += [x for x in list(svd_embedding.columns) if x not in ['userid']]\n",
    "                            \n",
    "    #userid_authorid svd\n",
    "    svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'svd_userid_authorid_embedding.pkl'))\n",
    "    df  = df.merge(svd_embedding,on = ['userid'],how='left')\n",
    "    dense += [x for x in list(svd_embedding.columns) if x not in ['userid']]\n",
    "    \n",
    "    #text svd\n",
    "    svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'texts_svd_embedding.pkl'))\n",
    "    svd_embedding['feedid']  = svd_embedding['feedid'].astype(np.int32) \n",
    "    df  = df.merge(svd_embedding,on = ['feedid'],how='left')\n",
    "    dense += [x for x in list(svd_embedding.columns) if x not in ['feedid']]\n",
    "    \n",
    "    return df, dense\n",
    "def myLeftjoin(left,right,on):\n",
    "    return left.merge(right[right[on].isin(left[on])].set_index(on),how='left',left_on=on,right_index=True)\n",
    "def getHistFeatures(df,hist_features):\n",
    "    dense = [x for x in hist_features.columns if x not in df.columns and  'hist_seq' not in x ]\n",
    "    varlen = [x for x in hist_features.columns if 'hist_seq' in x]\n",
    "    df = df.merge(hist_features[hist_features.userid.isin(df.userid.unique())][['userid','feedid','date_','device'] + dense],how = 'left',on = ['userid','feedid','date_','device'])\n",
    "    return (df,dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c04310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data: pd.DataFrame,feedinfo,dnn_feature_columns,batch_size=2048, shuffle=True):\n",
    "        self.data = data.copy()\n",
    "        self.target = ACTION_LIST\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(self.data.shape[0])\n",
    "        \n",
    "        self.feedinfo = feedinfo\n",
    "        self.feed_embeddings = loadPkl(os.path.join(FEATURE_PATH,'feedembedings.pkl'))\n",
    "#         self.user_feed_svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'svd_userid_feedid_embedding.pkl'))\n",
    "#         self.user_author_svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'svd_userid_authorid_embedding.pkl'))\n",
    "#         self.text_svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'texts_svd_embedding.pkl'))\n",
    "#         self.text_svd_embedding['feedid'] = self.text_svd_embedding['feedid'].astype(int)\n",
    "        \n",
    "        self.dnn_feature_columns = dnn_feature_columns\n",
    "        self.feature_names = get_feature_names(self.dnn_feature_columns)\n",
    "        \n",
    "        if self.shuffle:\n",
    "            print('shuffle data index ing...')\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return (self.data.shape[0] // self.batch_size) + 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexs = self.indexes[index * self.batch_size:(index + 1) *\n",
    "                                    self.batch_size]\n",
    "        batch_data = self.data.iloc[batch_indexs, :]\n",
    "        \n",
    "        return self.get_feature_on_batch(batch_data)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            print('shuffle data index ing...')\n",
    "            np.random.shuffle(self.indexes)\n",
    "    def on_epoch_begain(self):\n",
    "        if self.shuffle:\n",
    "            print('shuffle data index ing...')\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def get_feature_on_batch(self, batch):\n",
    "        \n",
    "#         batch = batch.merge(self.user_feed_svd_embedding,on='userid',how='left')\n",
    "#         batch = batch.merge(self.user_author_svd_embedding,on='userid',how='left')\n",
    "#         batch = batch.merge(self.text_svd_embedding,on='feedid',how='left')\n",
    "#         batch = batch.merge(self.feed_embeddings,on='feedid',how='left')\n",
    "        \n",
    "        x = {name: batch[name].values for name in self.feature_names}\n",
    "        for col in ['manual_tag_list','manual_keyword_list','machine_keyword_list']:\n",
    "            x[col] = np.array(batch[col].tolist())\n",
    "        y = [batch[y].values for y in ACTION_LIST]\n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b5c3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedinfo loading over...\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "data = loadPkl(USER_ACTION)\n",
    "data = data.head(1000000) if DEBUG else data\n",
    "feedinfo = loadFeedinfo()\n",
    "# feed_embeddings = loadPkl(os.path.join(FEATURE_PATH,'feedembedings.pkl'))\n",
    "\n",
    "# user_feed_svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'svd_userid_feedid_embedding.pkl'))\n",
    "# user_author_svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'svd_userid_authorid_embedding.pkl'))\n",
    "# text_svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'texts_svd_embedding.pkl'))\n",
    "embedding_dim = 8\n",
    "sparse_features = ['userid', 'feedid', 'authorid', 'bgm_song_id', 'bgm_singer_id' ]\n",
    "dense_features = ['videoplayseconds',]\n",
    "# dense_features += [x for x in list(user_feed_svd_embedding.columns) if x not in ['userid']]\n",
    "# dense_features += [x for x in list(user_author_svd_embedding.columns) if x not in ['userid']]\n",
    "# dense_features += [x for x in list(text_svd_embedding.columns) if x not in ['feedid']]\n",
    "# dense_features += [x for x in list(feed_embeddings.columns) if x not in ['feedid']]\n",
    "data = data.merge(feedinfo[[\n",
    "    'feedid', 'authorid', 'videoplayseconds', 'bgm_song_id',\n",
    "    'bgm_singer_id'\n",
    "] + ['manual_tag_list', 'manual_keyword_list', 'machine_keyword_list'\n",
    "     ]],\n",
    "                    how='left',\n",
    "                    on='feedid')\n",
    "\n",
    "#dense 特征处理\n",
    "data['videoplayseconds'] = data['videoplayseconds'].fillna(0, )\n",
    "data['videoplayseconds'] = np.log(data['videoplayseconds'] + 1.0)\n",
    "train = data[data.date_ != 14]\n",
    "val = data[data.date_==14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c7203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fixlen_feature_columns = [\n",
    "    SparseFeat(feat,\n",
    "               vocabulary_size = feedinfo[feat].max() + 1,\n",
    "               embedding_dim=embedding_dim) for feat in sparse_features if feat !='userid'\n",
    "] + [DenseFeat(feat, 1) for feat in dense_features\n",
    "] + [SparseFeat('userid',\n",
    "               vocabulary_size= data['userid'].max() + 1,\n",
    "               embedding_dim=embedding_dim)]\n",
    "tag_columns = [\n",
    "    VarLenSparseFeat(SparseFeat('manual_tag_list',\n",
    "                                vocabulary_size=TAG_MAX,\n",
    "                                embedding_dim=8),\n",
    "                     maxlen=4)\n",
    "]\n",
    "key_words_columns = [\n",
    "    VarLenSparseFeat(SparseFeat('manual_keyword_list',\n",
    "                                vocabulary_size=KEY_WORDS_MAX,\n",
    "                                embedding_dim=16),\n",
    "                     maxlen=4),\n",
    "    VarLenSparseFeat(SparseFeat('machine_keyword_list',\n",
    "                                vocabulary_size=KEY_WORDS_MAX,\n",
    "                                embedding_dim=16),\n",
    "                     maxlen=4),\n",
    "]\n",
    "dnn_feature_columns =  fixlen_feature_columns + tag_columns + key_words_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f50371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99959682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/deepctr/layers/utils.py:171: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/deepctr/layers/utils.py:199: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "manual_tag_list (InputLayer)    (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "manual_keyword_list (InputLayer (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "machine_keyword_list (InputLaye (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "feedid (InputLayer)             (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "authorid (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bgm_song_id (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bgm_singer_id (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "userid (InputLayer)             (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_seq_emb_manual_tag_list  (None, 4, 8)         2824        manual_tag_list[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_seq_emb_manual_keyword_l (None, 4, 16)        436352      manual_keyword_list[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "sparse_seq_emb_machine_keyword_ (None, 4, 16)        436352      machine_keyword_list[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_feedid (Embedding)   (None, 1, 8)         902976      feedid[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_authorid (Embedding) (None, 1, 8)         150312      authorid[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_bgm_song_id (Embeddi (None, 1, 8)         201280      bgm_song_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_bgm_singer_id (Embed (None, 1, 8)         140008      bgm_singer_id[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_userid (Embedding)   (None, 1, 8)         2001992     userid[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequence_pooling_layer (Sequenc (None, 1, 8)         0           sparse_seq_emb_manual_tag_list[0]\n",
      "__________________________________________________________________________________________________\n",
      "sequence_pooling_layer_1 (Seque (None, 1, 16)        0           sparse_seq_emb_manual_keyword_lis\n",
      "__________________________________________________________________________________________________\n",
      "sequence_pooling_layer_2 (Seque (None, 1, 16)        0           sparse_seq_emb_machine_keyword_li\n",
      "__________________________________________________________________________________________________\n",
      "no_mask (NoMask)                multiple             0           sparse_emb_feedid[0][0]          \n",
      "                                                                 sparse_emb_authorid[0][0]        \n",
      "                                                                 sparse_emb_bgm_song_id[0][0]     \n",
      "                                                                 sparse_emb_bgm_singer_id[0][0]   \n",
      "                                                                 sparse_emb_userid[0][0]          \n",
      "                                                                 sequence_pooling_layer[0][0]     \n",
      "                                                                 sequence_pooling_layer_1[0][0]   \n",
      "                                                                 sequence_pooling_layer_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "videoplayseconds (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 80)        0           no_mask[0][0]                    \n",
      "                                                                 no_mask[1][0]                    \n",
      "                                                                 no_mask[2][0]                    \n",
      "                                                                 no_mask[3][0]                    \n",
      "                                                                 no_mask[4][0]                    \n",
      "                                                                 no_mask[5][0]                    \n",
      "                                                                 no_mask[6][0]                    \n",
      "                                                                 no_mask[7][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_1 (NoMask)              (None, 1)            0           videoplayseconds[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 80)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           no_mask_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_2 (NoMask)              multiple             0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 81)           0           no_mask_2[0][0]                  \n",
      "                                                                 no_mask_2[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dnn (DNN)                       (None, 128)          27008       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mmoe_layer (MMOELayer)          [(None, 8), (None, 8 9600        dnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "mmoe_layer_1 (MMOELayer)        [(None, 8), (None, 8 9600        dnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "mmoe_layer_2 (MMOELayer)        [(None, 8), (None, 8 9600        dnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "average (Average)               (None, 8)            0           mmoe_layer[0][0]                 \n",
      "                                                                 mmoe_layer_1[0][0]               \n",
      "                                                                 mmoe_layer_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 8)            0           mmoe_layer[0][1]                 \n",
      "                                                                 mmoe_layer_1[0][1]               \n",
      "                                                                 mmoe_layer_2[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "average_2 (Average)             (None, 8)            0           mmoe_layer[0][2]                 \n",
      "                                                                 mmoe_layer_1[0][2]               \n",
      "                                                                 mmoe_layer_2[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "average_3 (Average)             (None, 8)            0           mmoe_layer[0][3]                 \n",
      "                                                                 mmoe_layer_1[0][3]               \n",
      "                                                                 mmoe_layer_2[0][3]               \n",
      "__________________________________________________________________________________________________\n",
      "average_4 (Average)             (None, 8)            0           mmoe_layer[0][4]                 \n",
      "                                                                 mmoe_layer_1[0][4]               \n",
      "                                                                 mmoe_layer_2[0][4]               \n",
      "__________________________________________________________________________________________________\n",
      "average_5 (Average)             (None, 8)            0           mmoe_layer[0][5]                 \n",
      "                                                                 mmoe_layer_1[0][5]               \n",
      "                                                                 mmoe_layer_2[0][5]               \n",
      "__________________________________________________________________________________________________\n",
      "average_6 (Average)             (None, 8)            0           mmoe_layer[0][6]                 \n",
      "                                                                 mmoe_layer_1[0][6]               \n",
      "                                                                 mmoe_layer_2[0][6]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            8           average[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            8           average_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            8           average_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            8           average_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            8           average_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            8           average_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            8           average_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "read_comment (PredictionLayer)  (None, 1)            1           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "like (PredictionLayer)          (None, 1)            1           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "click_avatar (PredictionLayer)  (None, 1)            1           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "forward (PredictionLayer)       (None, 1)            1           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "comment (PredictionLayer)       (None, 1)            1           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "follow (PredictionLayer)        (None, 1)            1           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "favorite (PredictionLayer)      (None, 1)            1           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,327,967\n",
      "Trainable params: 4,327,967\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "shuffle data index ing...\n"
     ]
    }
   ],
   "source": [
    "num_tasks = len(ACTION_LIST)\n",
    "train_model = MMOE(dnn_feature_columns, \n",
    "                   num_tasks=num_tasks,\n",
    "                   task_types = ['binary' for i in range(num_tasks)],\n",
    "                   task_names = ACTION_LIST,\n",
    "                   num_experts=5,\n",
    "                   multi_head_num = 3,\n",
    "                   tower_dnn_units_lists = [[16,8] for i in range(num_tasks) ])\n",
    "train_model.summary()\n",
    "train_loader = myDataGenerator(train,feedinfo,dnn_feature_columns,batch_size=4096)\n",
    "val_loader = myDataGenerator(val,feedinfo,dnn_feature_columns,batch_size=4096 * 4,shuffle = False) # shuffle 必须为False\n",
    "len(train_loader)\n",
    "train_model = multi_gpu_model(train_model, gpus=2)\n",
    "optimizer = tf.keras.optimizers.Adagrad(\n",
    "    lr=0.01, epsilon=1e-07,\n",
    ")\n",
    "train_model.compile(\"adagrad\", loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1080d15",
   "metadata": {},
   "source": [
    "## offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0162f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "  536/18013 [..............................] - ETA: 16:40 - loss: 0.3716 - read_comment_loss: 0.1319 - like_loss: 0.1183 - click_avatar_loss: 0.0489 - forward_loss: 0.0298 - comment_loss: 0.0088 - follow_loss: 0.0104 - favorite_loss: 0.0134Please check the latest version manually on https://pypi.org/project/deepctr/#history\n",
      "18013/18013 [==============================] - 811s 45ms/step - loss: 0.2740 - read_comment_loss: 0.0919 - like_loss: 0.0935 - click_avatar_loss: 0.0379 - forward_loss: 0.0214 - comment_loss: 0.0037 - follow_loss: 0.0055 - favorite_loss: 0.0081\n",
      "18013/18013 [==============================] - 809s 45ms/step - loss: 0.2502 - read_comment_loss: 0.0862 - like_loss: 0.0875 - click_avatar_loss: 0.0344 - forward_loss: 0.0190 - comment_loss: 0.0033 - follow_loss: 0.0048 - favorite_loss: 0.0063\n",
      "【UAUC：0.6688168684035513】 [0.6442163270878852, 0.6319739517051614, 0.732864862538752, 0.7154539690431767, 0.5770451726320346, 0.7111260719002528, 0.7524771871261724]\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adagrad object at 0x7ffa36ee7438>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "18013/18013 [==============================] - 820s 46ms/step - loss: 0.2450 - read_comment_loss: 0.0853 - like_loss: 0.0867 - click_avatar_loss: 0.0336 - forward_loss: 0.0182 - comment_loss: 0.0032 - follow_loss: 0.0046 - favorite_loss: 0.0060\n",
      "【UAUC：0.6714256216871646】 [0.6454274356105509, 0.6325404055900603, 0.7348875058440113, 0.719499716525733, 0.588191412350803, 0.7152915098310446, 0.7564444723251524]\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adagrad object at 0x7ffa36ee7438>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "18011/18013 [============================>.] - ETA: 0s - loss: 0.2420 - read_comment_loss: 0.0849 - like_loss: 0.0862 - click_avatar_loss: 0.0331 - forward_loss: 0.0177 - comment_loss: 0.0031 - follow_loss: 0.0045 - favorite_loss: 0.0058shuffle data index ing...\n",
      "18013/18013 [==============================] - 829s 46ms/step - loss: 0.2420 - read_comment_loss: 0.0849 - like_loss: 0.0862 - click_avatar_loss: 0.0331 - forward_loss: 0.0177 - comment_loss: 0.0031 - follow_loss: 0.0045 - favorite_loss: 0.0058\n",
      "【UAUC：0.6724157020173478】 [0.6452748300278229, 0.6330958680480433, 0.7345311288305045, 0.7205336532994379, 0.5962759783560465, 0.7177223660874967, 0.7574229465661096]\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adagrad object at 0x7ffa36ee7438>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "18013/18013 [==============================] - 809s 45ms/step - loss: 0.2400 - read_comment_loss: 0.0845 - like_loss: 0.0859 - click_avatar_loss: 0.0329 - forward_loss: 0.0175 - comment_loss: 0.0030 - follow_loss: 0.0045 - favorite_loss: 0.0057\n",
      "【UAUC：0.6731532994737466】 [0.6454044495170455, 0.6331759604763799, 0.7345229624088125, 0.722121250057007, 0.5988040755275661, 0.7194230198902839, 0.7604529433689026]\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adagrad object at 0x7ffa36ee7438>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    }
   ],
   "source": [
    "best_score = -1\n",
    "early_stop = 1\n",
    "no_imporove = 0\n",
    "for epoch in range(5):\n",
    "    history = train_model.fit(train_loader,\n",
    "                              epochs=1, verbose=1,workers = 8,use_multiprocessing=True,max_queue_size=100)\n",
    "    pred_ans = train_model.predict_generator(val_loader)\n",
    "    pred_ans = np.concatenate(pred_ans,1)\n",
    "    pred_ans = pd.DataFrame(pred_ans,columns=ACTION_LIST)\n",
    "    weightauc,uaucs = evaluate_deepctr(val_loader.data[ACTION_LIST],pred_ans,val_loader.data['userid'].values,ACTION_LIST)\n",
    "    \n",
    "    if best_score < weightauc:\n",
    "        best_score = weightauc\n",
    "        train_model.save_weights(os.path.join(MODEL_PATH,'tf_models/MMOE_offline'))\n",
    "        no_imporove = 0    \n",
    "    else :\n",
    "        no_imporove += 1\n",
    "    if no_imporove >= early_stop:\n",
    "        print('-----stoped on epoch %s ------- ' % (epoch))\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed9a707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7ff8eec48208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.load_weights(os.path.join(MODEL_PATH,'tf_models/MMOE_offline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4d81f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a9a4038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.6731532994737466, 0.6731532994737466)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_imporove , weightauc , best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad947054",
   "metadata": {},
   "source": [
    "# online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7693754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle data index ing...\n",
      "19652/19652 [==============================] - 894s 46ms/step - loss: 0.2391 - read_comment_loss: 0.0844 - like_loss: 0.0857 - click_avatar_loss: 0.0328 - forward_loss: 0.0174 - comment_loss: 0.0029 - follow_loss: 0.0044 - favorite_loss: 0.0057\n",
      "【UAUC：0.715024333901372】 [0.6894087927885463, 0.6640912978871467, 0.7687057346141821, 0.777389251111727, 0.6699674490840437, 0.7658881829525023, 0.7947509235255732]\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adagrad object at 0x7ffa36ee7438>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    }
   ],
   "source": [
    "data_loader = myDataGenerator(data,feedinfo,dnn_feature_columns,batch_size=4096)\n",
    "for epoch in range(1):\n",
    "    history = train_model.fit(data_loader,\n",
    "                              epochs=1, verbose=1,workers = 8,use_multiprocessing=True,max_queue_size=100)\n",
    "    pred_ans = train_model.predict_generator(val_loader)\n",
    "    pred_ans = np.concatenate(pred_ans,1)\n",
    "    pred_ans = pd.DataFrame(pred_ans,columns=ACTION_LIST)\n",
    "    weightauc,uaucs = evaluate_deepctr(val_loader.data[ACTION_LIST],pred_ans,val_loader.data['userid'].values,ACTION_LIST)\n",
    "train_model.save_weights(os.path.join(MODEL_PATH,'tf_models/MMOE_online'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfddabd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7个目标行为4252097条样本预测耗时（毫秒）：8824.591\n",
      "7个目标行为2000条样本平均预测耗时（毫秒）：4.151\n",
      "to_csv ok\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../../data/wedata/wechat_algo_data2/test_a.csv')\n",
    "test = test.merge(feedinfo[['feedid', 'authorid', 'videoplayseconds', 'bgm_song_id', 'bgm_singer_id']+ ['manual_tag_list','manual_keyword_list','machine_keyword_list']], how='left',on='feedid')\n",
    "test['videoplayseconds'] = test['videoplayseconds'].fillna(0, )\n",
    "test['videoplayseconds'] = np.log(test['videoplayseconds'] + 1.0)\n",
    "test[ACTION_LIST] = 0\n",
    "t1 = time()\n",
    "test_loader = myDataGenerator(test,feedinfo,dnn_feature_columns,shuffle=False,batch_size=4096*20)\n",
    "pred_ans = train_model.predict(test_loader)\n",
    "t2 = time()\n",
    "print('7个目标行为%d条样本预测耗时（毫秒）：%.3f' % (len(test), (t2 - t1) * 1000.0))\n",
    "ts = (t2 - t1) * 1000.0 / len(test) * 2000.0\n",
    "print('7个目标行为2000条样本平均预测耗时（毫秒）：%.3f' % ts)\n",
    "\n",
    "# 5.生成提交文件\n",
    "for i, action in enumerate(ACTION_LIST):\n",
    "    test[action] = pred_ans[i]\n",
    "test[['userid', 'feedid'] + ACTION_LIST].to_csv(os.path.join(SUMIT_DIR,'tf_mmoe_base4.csv'), index=None, float_format='%.6f')\n",
    "print('to_csv ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5365c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_csv ok\n"
     ]
    }
   ],
   "source": [
    "# 5.生成提交文件\n",
    "for i, action in enumerate(ACTION_LIST):\n",
    "    test[action] = pred_ans[i]\n",
    "test[['userid', 'feedid'] + ACTION_LIST].to_csv(os.path.join(SUMIT_DIR,'tf_mmoe_base3.csv'), index=None, float_format='%.6f')\n",
    "print('to_csv ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a31045e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>feedid</th>\n",
       "      <th>read_comment</th>\n",
       "      <th>like</th>\n",
       "      <th>click_avatar</th>\n",
       "      <th>forward</th>\n",
       "      <th>comment</th>\n",
       "      <th>follow</th>\n",
       "      <th>favorite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175282</td>\n",
       "      <td>50458</td>\n",
       "      <td>0.024931</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.025858</td>\n",
       "      <td>7.793009e-04</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>6.718934e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80036</td>\n",
       "      <td>42329</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>3.859997e-04</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>6.186068e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145791</td>\n",
       "      <td>85242</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.008639</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>1.952052e-05</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.084805e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28430</td>\n",
       "      <td>9425</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.043480</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>2.826899e-03</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>5.800337e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44393</td>\n",
       "      <td>11866</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>3.576279e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.642673e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252092</th>\n",
       "      <td>153322</td>\n",
       "      <td>51633</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>7.057190e-05</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>5.510747e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252093</th>\n",
       "      <td>39430</td>\n",
       "      <td>20147</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.356006e-05</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.129244e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252094</th>\n",
       "      <td>2524</td>\n",
       "      <td>89043</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.018232</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>3.284216e-05</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.564192e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252095</th>\n",
       "      <td>69629</td>\n",
       "      <td>27238</td>\n",
       "      <td>0.033721</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.018737</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>1.761019e-04</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>1.875758e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252096</th>\n",
       "      <td>177540</td>\n",
       "      <td>17432</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>3.269136e-06</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>7.214697e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4252097 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userid  feedid  read_comment      like  click_avatar   forward  \\\n",
       "0        175282   50458      0.024931  0.010128      0.001030  0.025858   \n",
       "1         80036   42329      0.008010  0.004921      0.012007  0.001349   \n",
       "2        145791   85242      0.000433  0.008639      0.000319  0.000313   \n",
       "3         28430    9425      0.005326  0.004971      0.043480  0.033652   \n",
       "4         44393   11866      0.000025  0.001973      0.000075  0.000180   \n",
       "...         ...     ...           ...       ...           ...       ...   \n",
       "4252092  153322   51633      0.000334  0.005208      0.003492  0.002972   \n",
       "4252093   39430   20147      0.003300  0.007864      0.000141  0.000056   \n",
       "4252094    2524   89043      0.000507  0.018232      0.002092  0.000521   \n",
       "4252095   69629   27238      0.033721  0.006551      0.018737  0.000892   \n",
       "4252096  177540   17432      0.000352  0.001487      0.001779  0.000086   \n",
       "\n",
       "              comment    follow      favorite  \n",
       "0        7.793009e-04  0.000272  6.718934e-04  \n",
       "1        3.859997e-04  0.001910  6.186068e-04  \n",
       "2        1.952052e-05  0.000012  1.084805e-05  \n",
       "3        2.826899e-03  0.025757  5.800337e-03  \n",
       "4        3.576279e-07  0.000002  8.642673e-07  \n",
       "...               ...       ...           ...  \n",
       "4252092  7.057190e-05  0.000343  5.510747e-04  \n",
       "4252093  1.356006e-05  0.000006  3.129244e-06  \n",
       "4252094  3.284216e-05  0.000200  2.564192e-04  \n",
       "4252095  1.761019e-04  0.001717  1.875758e-04  \n",
       "4252096  3.269136e-06  0.000046  7.214697e-06  \n",
       "\n",
       "[4252097 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['userid', 'feedid'] + ACTION_LIST]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
