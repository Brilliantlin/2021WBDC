{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR(目录): /home/tione/notebook\n",
      "INFO: Pandarallel will run on 14 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../config/')\n",
    "# BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "# sys.path.append(os.path.join(BASE_DIR, '../../config'))\n",
    "from config_prosper import *\n",
    "from my_deepctr_torch.inputs import (DenseFeat, SparseFeat, VarLenSparseFeat, get_feature_names,build_input_features)\n",
    "from mytools.utils.seed import seed_everything\n",
    "from mytools.utils.myfile import savePkl,loadPkl\n",
    "import gc\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "pd.set_option('display.max_columns', None)\n",
    "seed_everything(SEED)\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeedembeddings(df):\n",
    "    #feedembeddings 降维\n",
    "\n",
    "    feed_embedding_path = os.path.join(FEATURE_PATH,'feedembedings.pkl')\n",
    "    feed_embeddings = loadPkl(feed_embedding_path)\n",
    "    df = df.merge(feed_embeddings,on='feedid',how='left')\n",
    "    dense = [x for x in list(feed_embeddings.columns) if x != 'feedid' ]\n",
    "    \n",
    "    return df,dense\n",
    "\n",
    "def getSvdembeddings(df):\n",
    "    dense = []\n",
    "    #userid-feedid svd\n",
    "    svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'svd_userid_feedid_embedding.pkl'))\n",
    "    df = df.merge(svd_embedding,on = ['userid'],how='left')\n",
    "    dense += [x for x in list(svd_embedding.columns) if x not in ['userid']]\n",
    "                            \n",
    "    #userid_authorid svd\n",
    "    svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'svd_userid_authorid_embedding.pkl'))\n",
    "    df  = df.merge(svd_embedding,on = ['userid'],how='left')\n",
    "    dense += [x for x in list(svd_embedding.columns) if x not in ['userid']]\n",
    "    \n",
    "    #text svd\n",
    "    svd_embedding = loadPkl(os.path.join(FEATURE_PATH,'texts_svd_embedding.pkl'))\n",
    "    svd_embedding['feedid']  = svd_embedding['feedid'].astype(np.int32) \n",
    "    df  = df.merge(svd_embedding,on = ['feedid'],how='left')\n",
    "    dense += [x for x in list(svd_embedding.columns) if x not in ['feedid']]\n",
    "    \n",
    "    return df, dense\n",
    "def myLeftjoin(left,right,on):\n",
    "    return left.merge(right[right[on].isin(left[on])].set_index(on),how='left',left_on=on,right_index=True)\n",
    "def getHistFeatures(df,hist_features):\n",
    "    dense = [x for x in hist_features.columns if x not in df.columns and  'hist_seq' not in x ]\n",
    "    varlen = [x for x in hist_features.columns if 'hist_seq' in x]\n",
    "    df = df.merge(hist_features[hist_features.userid.isin(df.userid.unique())][['userid','feedid','date_','device'] + dense],how = 'left',on = ['userid','feedid','date_','device'])\n",
    "    return (df,dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "def myMerge(left,right,on):\n",
    "    return pd.concat()\n",
    "def getAllFeat(data_path,mode):\n",
    "    print('Mode : %s dealing feature...' % (mode))\n",
    "    assert mode == 'train' or mode == 'test'\n",
    "    feed_info = reduce_mem_usage(loadPkl(FEED_INFO)) \n",
    "    feed_embeddings = reduce_mem_usage(pd.read_csv(FEED_EMBEDDINGS))\n",
    "    if mode =='train':\n",
    "        # 存储各种ID信息全部\n",
    "        user_action_all = loadPkl(USER_ACTION) if not DEBUG else loadPkl(USER_ACTION).head(20000000)\n",
    "        user_action_all = user_action_all[user_action_all.date_ >=5]\n",
    "        IDS = {\n",
    "            'userid':user_action_all.userid.unique().tolist() + [UNK],\n",
    "            'feedid':feed_info.feedid.unique().tolist() + [UNK],\n",
    "            'authorid':feed_info.authorid.unique().tolist() + [UNK],\n",
    "            'bgm_song_id':feed_info.bgm_song_id.unique().tolist() + [UNK],\n",
    "            'bgm_singer_id':feed_info.bgm_singer_id.unique().tolist() + [UNK],\n",
    "        }\n",
    "\n",
    "        VAR_IDS = {}\n",
    "        DENSE = ['videoplayseconds']\n",
    "        all_dfs = []\n",
    "        \n",
    "        #encoder\n",
    "        for col in IDS:\n",
    "            encoder = LabelEncoder()\n",
    "            encoder.fit(IDS[col])\n",
    "            savePkl(encoder,os.path.join(MODEL_PATH,'ID_col_%s_encoder.pkl' % (col)))\n",
    "\n",
    "        begain_index = 0\n",
    "        window_size = 15000000\n",
    "        user_action_all = user_action_all.sample(frac=1)\n",
    "        hist_features = loadPkl('5days_feature.pkl')\n",
    "        hist_features = hist_features.fillna(0)\n",
    "        print(user_action_all.shape[0])\n",
    "        valid_data = []\n",
    "        while begain_index  < user_action_all.shape[0]:\n",
    "            print('处理数据%s - %s ......' % (begain_index,begain_index + window_size))\n",
    "            user_action = user_action_all.iloc[begain_index:begain_index+window_size]\n",
    "            df = user_action.merge(feed_info,on=['feedid'],how='left')\n",
    "            del user_action\n",
    "            df = df[['userid','feedid','date_','device'] + ACTION_LIST + ['authorid','bgm_song_id','bgm_singer_id','videoplayseconds']]\n",
    "            gc.collect()\n",
    "            #### merge feat #####\n",
    "            df,dense_tmp = getFeedembeddings(df)\n",
    "            DENSE += dense_tmp\n",
    "\n",
    "            df,dense_tmp = getSvdembeddings(df)\n",
    "            DENSE += dense_tmp\n",
    "\n",
    "            print('hist feature ...')\n",
    "            df,dense_tmp = getHistFeatures(df,hist_features)\n",
    "            DENSE += dense_tmp\n",
    "            \n",
    "            print('encoding ID 特征......')\n",
    "            df[list(IDS.keys())] = df[list(IDS.keys())].fillna(-1)\n",
    "            for col in IDS:\n",
    "                encoder = loadPkl(os.path.join(MODEL_PATH,'ID_col_%s_encoder.pkl' % (col)))\n",
    "                df[col] = encoder.transform(df[col])\n",
    "            \n",
    "            # 特征名定义\n",
    "            feature_columns = []\n",
    "            feature_columns += [SparseFeat(k,len(IDS[k]) + 1,embedding_dim=8) for k,v in IDS.items()]\n",
    "            feature_columns += [DenseFeat(k, 1) for k in DENSE]\n",
    "            feature_columns += [VarLenSparseFeat(SparseFeat(k,len(VAR_IDS[k]) + 1,embedding_dim = 8,),maxlen=MAX_LNE[k],combiner = 'mean')  for k,v in VAR_IDS.items()]\n",
    "            \n",
    "            df = reduce_mem_usage(df)\n",
    "            valid_data.append(df[df.date_==14])\n",
    "            df = df[df.date_!=14]\n",
    "#             dataloader = getDataloader(df,feature_columns,BATCH_SIZE)\n",
    "            #end\n",
    "            print('saving...')\n",
    "            savePkl(df,\"train_data_part%s.pkl\" % (begain_index//window_size))\n",
    "            begain_index += window_size\n",
    "#             break\n",
    "\n",
    "        del user_action_all\n",
    "        gc.collect()\n",
    "        valid_data = pd.concat(valid_data)\n",
    "        savePkl(valid_data,\"valid_data.pkl\")\n",
    "        savePkl((IDS,VAR_IDS,DENSE),os.path.join(MODEL_PATH,'feature_names.pkl'))\n",
    "        savePkl(feature_columns,os.path.join(MODEL_PATH,'feature_columns.pkl'))\n",
    "        return \n",
    "\n",
    "    else :\n",
    "        hist_features = loadPkl('5days_feature.pkl')\n",
    "        hist_features = hist_features.fillna(0)\n",
    "        df = reduce_mem_usage(pd.read_csv(data_path))\n",
    "        df = df.merge(feed_info,on=['feedid'],how='left')\n",
    "        df[ACTION_LIST] = 0\n",
    "        df = df[['userid','feedid','device'] + ACTION_LIST + ['authorid','bgm_song_id','bgm_singer_id','videoplayseconds']]\n",
    "        df['date_'] = END_DAY\n",
    "\n",
    "        IDS,VAR_IDS,DENSE = loadPkl(os.path.join(MODEL_PATH,'feature_names.pkl'))\n",
    "\n",
    "        #### merge feat #####\n",
    "        df,dense_tmp = getFeedembeddings(df)\n",
    "        DENSE += dense_tmp\n",
    "\n",
    "        df,dense_tmp = getSvdembeddings(df)\n",
    "        DENSE += dense_tmp\n",
    "\n",
    "        print('hist feature ...')\n",
    "        df,dense_tmp = getHistFeatures(df,hist_features)\n",
    "        DENSE += dense_tmp\n",
    "\n",
    "\n",
    "        df[list(IDS.keys())] = df[list(IDS.keys())].fillna(-1)\n",
    "        print('测试集encoding ID 特征......')\n",
    "        for col in IDS:\n",
    "            encoder = loadPkl(os.path.join(MODEL_PATH,'ID_col_%s_encoder.pkl' % (col)))\n",
    "            df[col] = encoder.transform(df[col])\n",
    "        feature_columns = loadPkl(os.path.join(MODEL_PATH,'feature_columns.pkl'))\n",
    "        return feature_columns,df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBaseFeat(data_path,mode):\n",
    "    print('Mode : %s dealing feature...' % (mode))\n",
    "    assert mode == 'train' or mode == 'test'\n",
    "    feed_info = reduce_mem_usage(loadPkl(FEED_INFO)) \n",
    "    feed_embeddings = reduce_mem_usage(pd.read_csv(FEED_EMBEDDINGS))\n",
    "    if mode =='train':\n",
    "        # 存储各种ID信息全部\n",
    "        user_action_all = loadPkl(USER_ACTION) if not DEBUG else loadPkl(USER_ACTION).head(20000000)\n",
    "        user_action_all = user_action_all[user_action_all.date_ >=5]\n",
    "        IDS = {\n",
    "            'userid':user_action_all.userid.unique().tolist() + [UNK],\n",
    "            'feedid':feed_info.feedid.unique().tolist() + [UNK],\n",
    "            'authorid':feed_info.authorid.unique().tolist() + [UNK],\n",
    "            'bgm_song_id':feed_info.bgm_song_id.unique().tolist() + [UNK],\n",
    "            'bgm_singer_id':feed_info.bgm_singer_id.unique().tolist() + [UNK],\n",
    "        }\n",
    "\n",
    "        VAR_IDS = {}\n",
    "        DENSE = ['videoplayseconds']\n",
    "        all_dfs = []\n",
    "        \n",
    "        #encoder\n",
    "        for col in IDS:\n",
    "            encoder = LabelEncoder()\n",
    "            encoder.fit(IDS[col])\n",
    "            savePkl(encoder,os.path.join(MODEL_PATH,'ID_col_%s_encoder.pkl' % (col)))\n",
    "\n",
    "        begain_index = 0\n",
    "        window_size = 45000000\n",
    "        user_action_all = user_action_all.sample(frac=1)\n",
    "        hist_features = loadPkl('5days_feature.pkl')\n",
    "        hist_features = hist_features.fillna(0)\n",
    "        print(user_action_all.shape[0])\n",
    "        valid_data = []\n",
    "        while begain_index  < user_action_all.shape[0]:\n",
    "            print('处理数据%s - %s ......' % (begain_index,begain_index + window_size))\n",
    "            user_action = user_action_all.iloc[begain_index:begain_index+window_size]\n",
    "            df = user_action.merge(feed_info,on=['feedid'],how='left')\n",
    "            del user_action\n",
    "            df = df[['userid','feedid','date_','device'] + ACTION_LIST + ['authorid','bgm_song_id','bgm_singer_id','videoplayseconds']]\n",
    "            gc.collect()\n",
    "            #### merge feat #####\n",
    "#             df,dense_tmp = getFeedembeddings(df)\n",
    "#             DENSE += dense_tmp\n",
    "\n",
    "#             df,dense_tmp = getSvdembeddings(df)\n",
    "#             DENSE += dense_tmp\n",
    "\n",
    "#             print('hist feature ...')\n",
    "#             df,dense_tmp = getHistFeatures(df,hist_features)\n",
    "#             DENSE += dense_tmp\n",
    "            \n",
    "            print('encoding ID 特征......')\n",
    "            df[list(IDS.keys())] = df[list(IDS.keys())].fillna(-1)\n",
    "            for col in IDS:\n",
    "                encoder = loadPkl(os.path.join(MODEL_PATH,'ID_col_%s_encoder.pkl' % (col)))\n",
    "                df[col] = encoder.transform(df[col])\n",
    "            \n",
    "            # 特征名定义\n",
    "            feature_columns = []\n",
    "            feature_columns += [SparseFeat(k,len(IDS[k]) + 1,embedding_dim=8) for k,v in IDS.items()]\n",
    "            feature_columns += [DenseFeat(k, 1) for k in DENSE]\n",
    "            feature_columns += [VarLenSparseFeat(SparseFeat(k,len(VAR_IDS[k]) + 1,embedding_dim = 8,),maxlen=MAX_LNE[k],combiner = 'mean')  for k,v in VAR_IDS.items()]\n",
    "            \n",
    "            df = reduce_mem_usage(df)\n",
    "            valid_data.append(df[df.date_==14])\n",
    "            df = df[df.date_!=14]\n",
    "#             dataloader = getDataloader(df,feature_columns,BATCH_SIZE)\n",
    "            #end\n",
    "            print('saving...')\n",
    "            savePkl(df,\"train_data_part%s.pkl\" % (begain_index//window_size))\n",
    "            begain_index += window_size\n",
    "#             break\n",
    "\n",
    "        del user_action_all\n",
    "        gc.collect()\n",
    "        valid_data = pd.concat(valid_data)\n",
    "        savePkl(valid_data,\"valid_data.pkl\")\n",
    "        savePkl((IDS,VAR_IDS,DENSE),os.path.join(MODEL_PATH,'feature_names.pkl'))\n",
    "        savePkl(feature_columns,os.path.join(MODEL_PATH,'feature_columns.pkl'))\n",
    "        return \n",
    "\n",
    "    else :\n",
    "        df = reduce_mem_usage(pd.read_csv(data_path))\n",
    "        df = df.merge(feed_info,on=['feedid'],how='left')\n",
    "        df[ACTION_LIST] = 0\n",
    "        df = df[['userid','feedid','device'] + ACTION_LIST + ['authorid','bgm_song_id','bgm_singer_id','videoplayseconds']]\n",
    "        df['date_'] = END_DAY\n",
    "\n",
    "        IDS,VAR_IDS,DENSE = loadPkl(os.path.join(MODEL_PATH,'feature_names.pkl'))\n",
    "\n",
    "        #### merge feat #####\n",
    "#         df,dense_tmp = getFeedembeddings(df)\n",
    "#         DENSE += dense_tmp\n",
    "\n",
    "#         df,dense_tmp = getSvdembeddings(df)\n",
    "#         DENSE += dense_tmp\n",
    "\n",
    "#         print('hist feature ...')\n",
    "#         df,dense_tmp = getHistFeatures(df,hist_features)\n",
    "#         DENSE += dense_tmp\n",
    "\n",
    "\n",
    "        df[list(IDS.keys())] = df[list(IDS.keys())].fillna(-1)\n",
    "        print('测试集encoding ID 特征......')\n",
    "        for col in IDS:\n",
    "            encoder = loadPkl(os.path.join(MODEL_PATH,'ID_col_%s_encoder.pkl' % (col)))\n",
    "            df[col] = encoder.transform(df[col])\n",
    "        feature_columns = loadPkl(os.path.join(MODEL_PATH,'feature_columns.pkl'))\n",
    "        return feature_columns,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode : train dealing feature...\n",
      "Mem. usage decreased to  9.54 Mb (21.7% reduction)\n",
      "Mem. usage decreased to  1.22 Mb (25.0% reduction)\n",
      "58538090\n",
      "处理数据0 - 15000000 ......\n",
      "hist feature ...\n",
      "encoding ID 特征......\n",
      "Mem. usage decreased to 5965.23 Mb (59.2% reduction)\n",
      "saving...\n",
      "处理数据15000000 - 30000000 ......\n",
      "hist feature ...\n",
      "encoding ID 特征......\n",
      "Mem. usage decreased to 5965.23 Mb (59.2% reduction)\n",
      "saving...\n",
      "处理数据30000000 - 45000000 ......\n",
      "hist feature ...\n",
      "encoding ID 特征......\n",
      "Mem. usage decreased to 5965.23 Mb (59.2% reduction)\n",
      "saving...\n",
      "处理数据45000000 - 60000000 ......\n",
      "hist feature ...\n",
      "encoding ID 特征......\n",
      "Mem. usage decreased to 5383.86 Mb (59.2% reduction)\n",
      "saving...\n",
      "Time cost: 3525.20 s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    t1 = time.time()\n",
    "    getFeat('None','train')\n",
    "    print('Time cost: %.2f s'%(time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode : test dealing feature...\n",
      "Mem. usage decreased to  9.54 Mb (21.7% reduction)\n",
      "Mem. usage decreased to  1.22 Mb (25.0% reduction)\n",
      "Mem. usage decreased to 36.50 Mb (62.5% reduction)\n",
      "hist feature ...\n",
      "测试集encoding ID 特征......\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [218, 241, 550, 920, 1295, 1448, 1998, 2183, 2421, 2733, 2755, 2768, 2876, 2925, 3228, 3594, 3612, 3877, 3913, 4119, 5531, 5588, 6271, 6312, 6376, 6441, 6906, 7483, 7787, 8089, 9687, 10056, 10154, 10270, 11007, 11378, 11380, 11699, 11973, 12547, 12660, 12990, 13446, 13478, 13646, 13790, 14250, 14258, 14510, 14639, 15709, 16680, 16780, 16788, 16955, 17596, 17924, 19017, 19076, 20251, 20564, 21018, 21070, 21264, 21454, 22760, 22901, 23259, 24714, 24854, 24886, 25086, 25145, 25214, 25997, 27023, 27254, 28258, 28863, 30290, 30339, 31472, 32156, 33153, 33210, 33498, 33739, 34135, 34343, 34354, 34434, 34436, 34510, 36060, 37053, 37151, 38466, 38898, 39899, 40077, 41097, 41623, 42115, 42264, 42487, 42593, 42834, 42989, 43078, 43636, 43925, 43967, 44162, 44726, 45135, 45251, 45906, 46025, 46072, 46559, 46817, 47377, 47787, 48040, 48740, 49301, 49654, 49735, 49861, 50082, 50153, 50170, 50368, 50596, 50822, 50888, 51571, 51963, 53053, 53647, 54317, 54443, 54566, 55234, 55424, 55599, 55890, 55965, 55973, 56390, 57240, 57732, 58206, 58252, 58383, 60062, 60602, 60989, 62157, 62165, 62268, 63054, 63151, 63833, 64245, 64523, 64823, 64937, 65713, 66544, 68338, 69102, 69482, 69668, 70168, 70547, 71804, 71924, 72247, 72319, 72333, 72485, 72687, 72853, 72910, 73805, 75075, 75677, 76554, 76589, 76591, 78320, 78375, 78511, 78823, 79096, 79581, 80332, 81553, 81649, 81920, 82845, 83060, 83694, 83927, 83963, 84947, 85147, 85159, 85935, 86349, 86467, 86574, 87089, 87164, 87381, 88332, 88590, 88938, 89014, 89111, 90661, 90704, 90812, 91222, 92467, 92693, 92820, 93008, 93247, 93384, 93388, 93723, 94306, 94374, 94391, 94614, 95275, 95731, 96098, 96164, 96255, 96718, 96784, 97060, 97099, 97537, 97762, 97975, 98464, 98531, 98718, 99852, 100443, 100849, 104278, 105117, 105291, 105362, 105429, 105822, 105836, 105854, 106843, 108482, 108859, 108991, 110178, 110311, 111329, 111402, 111573, 111666, 112025, 112058, 113420, 113916, 114560, 114756, 115771, 116084, 117065, 117453, 118004, 118295, 118367, 118953, 119145, 119316, 119362, 120045, 120116, 121364, 121382, 121402, 121558, 122373, 122498, 122850, 123417, 124659, 125060, 125093, 125671, 125800, 126271, 126726, 127016, 127111, 127844, 128119, 128132, 128151, 128886, 129192, 129501, 129680, 130038, 130126, 130561, 131175, 132232, 132535, 132587, 132716, 132752, 133721, 134087, 134234, 134274, 134717, 134977, 135517, 135912, 136514, 137804, 137921, 138087, 138124, 138377, 138479, 138766, 138813, 138889, 139026, 139880, 140444, 140684, 141080, 141774, 141811, 141900, 143126, 143540, 144252, 145820, 145924, 146214, 146895, 149409, 149460, 149637, 151156, 151412, 151797, 151808, 151820, 152500, 152742, 153251, 153464, 153963, 154171, 155449, 155470, 155835, 156881, 157254, 157343, 157722, 157744, 158282, 158356, 159480, 159617, 159820, 160894, 161210, 161365, 162056, 162480, 162593, 163318, 164098, 164203, 164696, 165396, 165723, 166568, 167188, 167635, 168043, 168166, 168204, 168937, 168941, 169560, 170249, 170370, 170817, 171687, 171694, 171799, 172080, 172481, 172813, 173640, 173644, 173675, 174198, 174520, 174758, 175316, 175837, 175915, 176530, 176624, 176785, 177196, 177788, 178717, 179395, 181796, 182194, 182727, 182860, 183185, 183741, 184073, 185000, 185173, 185541, 186046, 186361, 186453, 187165, 188135, 188252, 188270, 188934, 188996, 190420, 190466, 191487, 191594, 191595, 192150, 192509, 193496, 193505, 193815, 194139, 194831, 194923, 195093, 195218, 196153, 196851, 197474, 197903, 197997, 199986, 200902, 201163, 201265, 201299, 202688, 202881, 204826, 204839, 205359, 206141, 208115, 209308, 209312, 209633, 210945, 211081, 211385, 211506, 211557, 211945, 212010, 212113, 212900, 213285, 213473, 213907, 215048, 215162, 215435, 216166, 216647, 216649, 217007, 217239, 217241, 217755, 217998, 219021, 219022, 219747, 219925, 220547, 220777, 220826, 221715, 222165, 224050, 224521, 224892, 224967, 225545, 226102, 226190, 226518, 227204, 227240, 227272, 227699, 227963, 228221, 228334, 229202, 229919, 230030, 231041, 231574, 231627, 231804, 232397, 232920, 232930, 233091, 233234, 233648, 234761, 234808, 235688, 235795, 235997, 236105, 236614, 236959, 237548, 239259, 239560, 240449, 240951, 241550, 243066, 243905, 244081, 244384, 244732, 245426, 245659, 245751, 247780, 247978, 248128, 249002, 249776, 249886]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-55a90f18e2ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mIDS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadPkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ID_col_%s_encoder.pkl'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mfeature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadPkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'feature_columns.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m#     return feature_columns,df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tione/notebook/envs/wbdc2021_prosper/lib/python3.6/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tione/notebook/envs/wbdc2021_prosper/lib/python3.6/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         return _encode_numpy(values, uniques, encode,\n\u001b[0;32m--> 122\u001b[0;31m                              check_unknown=check_unknown)\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tione/notebook/envs/wbdc2021_prosper/lib/python3.6/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[0;32m---> 51\u001b[0;31m                                  % str(diff))\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [218, 241, 550, 920, 1295, 1448, 1998, 2183, 2421, 2733, 2755, 2768, 2876, 2925, 3228, 3594, 3612, 3877, 3913, 4119, 5531, 5588, 6271, 6312, 6376, 6441, 6906, 7483, 7787, 8089, 9687, 10056, 10154, 10270, 11007, 11378, 11380, 11699, 11973, 12547, 12660, 12990, 13446, 13478, 13646, 13790, 14250, 14258, 14510, 14639, 15709, 16680, 16780, 16788, 16955, 17596, 17924, 19017, 19076, 20251, 20564, 21018, 21070, 21264, 21454, 22760, 22901, 23259, 24714, 24854, 24886, 25086, 25145, 25214, 25997, 27023, 27254, 28258, 28863, 30290, 30339, 31472, 32156, 33153, 33210, 33498, 33739, 34135, 34343, 34354, 34434, 34436, 34510, 36060, 37053, 37151, 38466, 38898, 39899, 40077, 41097, 41623, 42115, 42264, 42487, 42593, 42834, 42989, 43078, 43636, 43925, 43967, 44162, 44726, 45135, 45251, 45906, 46025, 46072, 46559, 46817, 47377, 47787, 48040, 48740, 49301, 49654, 49735, 49861, 50082, 50153, 50170, 50368, 50596, 50822, 50888, 51571, 51963, 53053, 53647, 54317, 54443, 54566, 55234, 55424, 55599, 55890, 55965, 55973, 56390, 57240, 57732, 58206, 58252, 58383, 60062, 60602, 60989, 62157, 62165, 62268, 63054, 63151, 63833, 64245, 64523, 64823, 64937, 65713, 66544, 68338, 69102, 69482, 69668, 70168, 70547, 71804, 71924, 72247, 72319, 72333, 72485, 72687, 72853, 72910, 73805, 75075, 75677, 76554, 76589, 76591, 78320, 78375, 78511, 78823, 79096, 79581, 80332, 81553, 81649, 81920, 82845, 83060, 83694, 83927, 83963, 84947, 85147, 85159, 85935, 86349, 86467, 86574, 87089, 87164, 87381, 88332, 88590, 88938, 89014, 89111, 90661, 90704, 90812, 91222, 92467, 92693, 92820, 93008, 93247, 93384, 93388, 93723, 94306, 94374, 94391, 94614, 95275, 95731, 96098, 96164, 96255, 96718, 96784, 97060, 97099, 97537, 97762, 97975, 98464, 98531, 98718, 99852, 100443, 100849, 104278, 105117, 105291, 105362, 105429, 105822, 105836, 105854, 106843, 108482, 108859, 108991, 110178, 110311, 111329, 111402, 111573, 111666, 112025, 112058, 113420, 113916, 114560, 114756, 115771, 116084, 117065, 117453, 118004, 118295, 118367, 118953, 119145, 119316, 119362, 120045, 120116, 121364, 121382, 121402, 121558, 122373, 122498, 122850, 123417, 124659, 125060, 125093, 125671, 125800, 126271, 126726, 127016, 127111, 127844, 128119, 128132, 128151, 128886, 129192, 129501, 129680, 130038, 130126, 130561, 131175, 132232, 132535, 132587, 132716, 132752, 133721, 134087, 134234, 134274, 134717, 134977, 135517, 135912, 136514, 137804, 137921, 138087, 138124, 138377, 138479, 138766, 138813, 138889, 139026, 139880, 140444, 140684, 141080, 141774, 141811, 141900, 143126, 143540, 144252, 145820, 145924, 146214, 146895, 149409, 149460, 149637, 151156, 151412, 151797, 151808, 151820, 152500, 152742, 153251, 153464, 153963, 154171, 155449, 155470, 155835, 156881, 157254, 157343, 157722, 157744, 158282, 158356, 159480, 159617, 159820, 160894, 161210, 161365, 162056, 162480, 162593, 163318, 164098, 164203, 164696, 165396, 165723, 166568, 167188, 167635, 168043, 168166, 168204, 168937, 168941, 169560, 170249, 170370, 170817, 171687, 171694, 171799, 172080, 172481, 172813, 173640, 173644, 173675, 174198, 174520, 174758, 175316, 175837, 175915, 176530, 176624, 176785, 177196, 177788, 178717, 179395, 181796, 182194, 182727, 182860, 183185, 183741, 184073, 185000, 185173, 185541, 186046, 186361, 186453, 187165, 188135, 188252, 188270, 188934, 188996, 190420, 190466, 191487, 191594, 191595, 192150, 192509, 193496, 193505, 193815, 194139, 194831, 194923, 195093, 195218, 196153, 196851, 197474, 197903, 197997, 199986, 200902, 201163, 201265, 201299, 202688, 202881, 204826, 204839, 205359, 206141, 208115, 209308, 209312, 209633, 210945, 211081, 211385, 211506, 211557, 211945, 212010, 212113, 212900, 213285, 213473, 213907, 215048, 215162, 215435, 216166, 216647, 216649, 217007, 217239, 217241, 217755, 217998, 219021, 219022, 219747, 219925, 220547, 220777, 220826, 221715, 222165, 224050, 224521, 224892, 224967, 225545, 226102, 226190, 226518, 227204, 227240, 227272, 227699, 227963, 228221, 228334, 229202, 229919, 230030, 231041, 231574, 231627, 231804, 232397, 232920, 232930, 233091, 233234, 233648, 234761, 234808, 235688, 235795, 235997, 236105, 236614, 236959, 237548, 239259, 239560, 240449, 240951, 241550, 243066, 243905, 244081, 244384, 244732, 245426, 245659, 245751, 247780, 247978, 248128, 249002, 249776, 249886]"
     ]
    }
   ],
   "source": [
    "mode = 'test'\n",
    "DEBUG = False\n",
    "data_path = os.path.join(SRC_DIR,'data/wedata/wechat_algo_data2/test_a.csv')\n",
    "print('Mode : %s dealing feature...' % (mode))\n",
    "assert mode == 'train' or mode == 'test'\n",
    "feed_info = reduce_mem_usage(loadPkl(FEED_INFO)) \n",
    "feed_embeddings = reduce_mem_usage(pd.read_csv(FEED_EMBEDDINGS))\n",
    "if mode =='train':\n",
    "    # 存储各种ID信息全部\n",
    "    user_action_all = loadPkl(USER_ACTION) if not DEBUG else loadPkl(USER_ACTION).head(20000000)\n",
    "    user_action_all = user_action_all[user_action_all.date_ >=5]\n",
    "    IDS = {\n",
    "        'userid':user_action_all.userid.unique().tolist() + [UNK],\n",
    "        'feedid':feed_info.feedid.unique().tolist() + [UNK],\n",
    "        'authorid':feed_info.authorid.unique().tolist() + [UNK],\n",
    "        'bgm_song_id':feed_info.bgm_song_id.unique().tolist() + [UNK],\n",
    "        'bgm_singer_id':feed_info.bgm_singer_id.unique().tolist() + [UNK],\n",
    "    }\n",
    "\n",
    "    VAR_IDS = {}\n",
    "    DENSE = ['videoplayseconds']\n",
    "    all_dfs = []\n",
    "\n",
    "    #encoder\n",
    "    for col in IDS:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(IDS[col])\n",
    "        savePkl(encoder,os.path.join(MODEL_PATH,'ID_col_%s_encoder.pkl' % (col)))\n",
    "\n",
    "    begain_index = 0\n",
    "    window_size = 15000000\n",
    "    user_action_all = user_action_all.sample(frac=1)\n",
    "    hist_features = loadPkl('5days_feature.pkl')\n",
    "    hist_features = hist_features.fillna(0)\n",
    "    print(user_action_all.shape[0])\n",
    "    valid_data = []\n",
    "    while begain_index  < user_action_all.shape[0]:\n",
    "        print('处理数据%s - %s ......' % (begain_index,begain_index + window_size))\n",
    "        user_action = user_action_all.iloc[begain_index:begain_index+window_size]\n",
    "        df = user_action.merge(feed_info,on=['feedid'],how='left')\n",
    "        del user_action\n",
    "        df = df[['userid','feedid','date_','device'] + ACTION_LIST + ['authorid','bgm_song_id','bgm_singer_id','videoplayseconds']]\n",
    "        gc.collect()\n",
    "        #### merge feat #####\n",
    "        df,dense_tmp = getFeedembeddings(df)\n",
    "        DENSE += dense_tmp\n",
    "\n",
    "        df,dense_tmp = getSvdembeddings(df)\n",
    "        DENSE += dense_tmp\n",
    "\n",
    "        print('hist feature ...')\n",
    "        df,dense_tmp = getHistFeatures(df,hist_features)\n",
    "        DENSE += dense_tmp\n",
    "\n",
    "        print('encoding ID 特征......')\n",
    "        df[list(IDS.keys())] = df[list(IDS.keys())].fillna(-1)\n",
    "        for col in IDS:\n",
    "            encoder = loadPkl(os.path.join(MODEL_PATH,'ID_col_%s_encoder.pkl' % (col)))\n",
    "            df[col] = encoder.transform(df[col])\n",
    "\n",
    "        # 特征名定义\n",
    "        feature_columns = []\n",
    "        feature_columns += [SparseFeat(k,len(IDS[k]) + 1,embedding_dim=8) for k,v in IDS.items()]\n",
    "        feature_columns += [DenseFeat(k, 1) for k in DENSE]\n",
    "        feature_columns += [VarLenSparseFeat(SparseFeat(k,len(VAR_IDS[k]) + 1,embedding_dim = 8,),maxlen=MAX_LNE[k],combiner = 'mean')  for k,v in VAR_IDS.items()]\n",
    "\n",
    "        df = reduce_mem_usage(df)\n",
    "        valid_data.append(df[df.date_==14])\n",
    "        df = df[df.date_!=14]\n",
    "#             dataloader = getDataloader(df,feature_columns,BATCH_SIZE)\n",
    "        #end\n",
    "        print('saving...')\n",
    "        savePkl(df,\"train_data_part%s.pkl\" % (begain_index//window_size))\n",
    "        begain_index += window_size\n",
    "#             break\n",
    "\n",
    "    del user_action_all\n",
    "    gc.collect()\n",
    "    valid_data = pd.concat(valid_data)\n",
    "    savePkl(valid_data,\"valid_data.pkl\")\n",
    "    savePkl((IDS,VAR_IDS,DENSE),os.path.join(MODEL_PATH,'feature_names.pkl'))\n",
    "    savePkl(feature_columns,os.path.join(MODEL_PATH,'feature_columns.pkl'))\n",
    "#     return \n",
    "\n",
    "else :\n",
    "    hist_features = loadPkl('5days_feature.pkl')\n",
    "    hist_features = hist_features.fillna(0)\n",
    "    df = reduce_mem_usage(pd.read_csv(data_path))\n",
    "    df = df.merge(feed_info,on=['feedid'],how='left')\n",
    "    df[ACTION_LIST] = 0\n",
    "    df = df[['userid','feedid','device'] + ACTION_LIST + ['authorid','bgm_song_id','bgm_singer_id','videoplayseconds']]\n",
    "    df['date_'] = END_DAY\n",
    "\n",
    "    IDS,VAR_IDS,DENSE = loadPkl(os.path.join(MODEL_PATH,'feature_names.pkl'))\n",
    "\n",
    "    #### merge feat #####\n",
    "    df,dense_tmp = getFeedembeddings(df)\n",
    "    DENSE += dense_tmp\n",
    "\n",
    "    df,dense_tmp = getSvdembeddings(df)\n",
    "    DENSE += dense_tmp\n",
    "\n",
    "    print('hist feature ...')\n",
    "    df,dense_tmp = getHistFeatures(df,hist_features)\n",
    "    DENSE += dense_tmp\n",
    "\n",
    "\n",
    "    df[list(IDS.keys())] = df[list(IDS.keys())].fillna(-1)\n",
    "    print('测试集encoding ID 特征......')\n",
    "    for col in IDS:\n",
    "        encoder = loadPkl(os.path.join(MODEL_PATH,'ID_col_%s_encoder.pkl' % (col)))\n",
    "        df[col] = encoder.transform(df[col])\n",
    "    feature_columns = loadPkl(os.path.join(MODEL_PATH,'feature_columns.pkl'))\n",
    "#     return feature_columns,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_wbdc2021_prosper",
   "language": "python",
   "name": "conda_wbdc2021_prosper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
